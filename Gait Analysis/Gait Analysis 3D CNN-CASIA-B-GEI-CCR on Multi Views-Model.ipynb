{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X = X/255.0\n",
    "\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from keras.layers import Dropout, Input, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib.pyplot import cm\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13219, 120, 120, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X.reshape(X.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X_train, X_tes, y_train, y_tes = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=X_tes[:1983]\n",
    "X_val.shape\n",
    "X_test=X_tes[1983:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val=y_tes[:1983]\n",
    "y_val.shape\n",
    "y_test=y_tes[1983:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "## input layer\n",
    "input_layer = Input((30, 30,16, 1))\n",
    "\n",
    "## convolutional layers\n",
    "conv_layer1 = Conv3D(filters=8, kernel_size=(3, 3, 3), activation='relu')(input_layer)\n",
    "conv_layer2 = Conv3D(filters=16, kernel_size=(3, 3, 3), activation='relu')(conv_layer1)\n",
    "\n",
    "## add max pooling to obtain the most imformatic features\n",
    "pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer2)\n",
    "\n",
    "conv_layer3 = Conv3D(filters=32, kernel_size=(3, 3, 3), activation='relu')(pooling_layer1)\n",
    "conv_layer4 = Conv3D(filters=64, kernel_size=(3, 3, 3), activation='relu')(conv_layer3)\n",
    "pooling_layer2 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer4)\n",
    "\n",
    "## perform batch normalization on the convolution outputs before feeding it to MLP architecture\n",
    "pooling_layer2 = BatchNormalization()(pooling_layer2)\n",
    "flatten_layer = Flatten()(pooling_layer2)\n",
    "\n",
    "## create an MLP architecture with dense layers : 4096 -> 512 -> 10\n",
    "## add dropouts to avoid overfitting / perform regularization\n",
    "dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
    "dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "dense_layer2 = Dense(units=512, activation='relu')(dense_layer1)\n",
    "dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "output_layer = Dense(units=124, activation='softmax')(dense_layer2)\n",
    "\n",
    "## define the model with input layer and output layer\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30, 30, 16, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 28, 28, 14, 8)     224       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 26, 12, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 13, 13, 6, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 11, 11, 4, 32)     13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 9, 9, 2, 64)       55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 4, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 124)               63612     \n",
      "=================================================================\n",
      "Total params: 3,285,068\n",
      "Trainable params: 3,284,940\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 9253 samples, validate on 1983 samples\n",
      "Epoch 1/150\n",
      "9253/9253 [==============================] - 11s 1ms/step - loss: 4.8220 - acc: 0.0094 - sparse_top_k_categorical_accuracy: 0.0454 - val_loss: 4.8208 - val_acc: 0.0055 - val_sparse_top_k_categorical_accuracy: 0.0454\n",
      "Epoch 2/150\n",
      "9253/9253 [==============================] - 7s 717us/step - loss: 4.7710 - acc: 0.0176 - sparse_top_k_categorical_accuracy: 0.0712 - val_loss: 4.8845 - val_acc: 0.0111 - val_sparse_top_k_categorical_accuracy: 0.0454\n",
      "Epoch 3/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 4.5180 - acc: 0.0390 - sparse_top_k_categorical_accuracy: 0.1429 - val_loss: 4.4184 - val_acc: 0.0373 - val_sparse_top_k_categorical_accuracy: 0.1609\n",
      "Epoch 4/150\n",
      "9253/9253 [==============================] - 7s 720us/step - loss: 3.9523 - acc: 0.1034 - sparse_top_k_categorical_accuracy: 0.2991 - val_loss: 5.7020 - val_acc: 0.0530 - val_sparse_top_k_categorical_accuracy: 0.1165\n",
      "Epoch 5/150\n",
      "9253/9253 [==============================] - 7s 717us/step - loss: 3.1541 - acc: 0.2257 - sparse_top_k_categorical_accuracy: 0.5197 - val_loss: 4.2882 - val_acc: 0.0918 - val_sparse_top_k_categorical_accuracy: 0.3369\n",
      "Epoch 6/150\n",
      "9253/9253 [==============================] - 7s 715us/step - loss: 2.3492 - acc: 0.3831 - sparse_top_k_categorical_accuracy: 0.7188 - val_loss: 2.3435 - val_acc: 0.3530 - val_sparse_top_k_categorical_accuracy: 0.7151\n",
      "Epoch 7/150\n",
      "9253/9253 [==============================] - 7s 716us/step - loss: 1.7334 - acc: 0.5287 - sparse_top_k_categorical_accuracy: 0.8415 - val_loss: 2.1250 - val_acc: 0.4070 - val_sparse_top_k_categorical_accuracy: 0.7574\n",
      "Epoch 8/150\n",
      "9253/9253 [==============================] - 7s 717us/step - loss: 1.3008 - acc: 0.6357 - sparse_top_k_categorical_accuracy: 0.9039 - val_loss: 1.5979 - val_acc: 0.5260 - val_sparse_top_k_categorical_accuracy: 0.8517\n",
      "Epoch 9/150\n",
      "9253/9253 [==============================] - 7s 716us/step - loss: 1.0068 - acc: 0.7151 - sparse_top_k_categorical_accuracy: 0.9360 - val_loss: 1.7611 - val_acc: 0.5532 - val_sparse_top_k_categorical_accuracy: 0.8361\n",
      "Epoch 10/150\n",
      "9253/9253 [==============================] - 7s 714us/step - loss: 0.7887 - acc: 0.7740 - sparse_top_k_categorical_accuracy: 0.9606 - val_loss: 6.7531 - val_acc: 0.1316 - val_sparse_top_k_categorical_accuracy: 0.3313\n",
      "Epoch 11/150\n",
      "9253/9253 [==============================] - 7s 707us/step - loss: 0.6109 - acc: 0.8237 - sparse_top_k_categorical_accuracy: 0.9753 - val_loss: 0.5196 - val_acc: 0.8593 - val_sparse_top_k_categorical_accuracy: 0.9803\n",
      "Epoch 12/150\n",
      "9253/9253 [==============================] - 7s 716us/step - loss: 0.5073 - acc: 0.8499 - sparse_top_k_categorical_accuracy: 0.9841 - val_loss: 0.6679 - val_acc: 0.7907 - val_sparse_top_k_categorical_accuracy: 0.9652\n",
      "Epoch 13/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.4158 - acc: 0.8780 - sparse_top_k_categorical_accuracy: 0.9894 - val_loss: 0.7784 - val_acc: 0.7756 - val_sparse_top_k_categorical_accuracy: 0.9536\n",
      "Epoch 14/150\n",
      "9253/9253 [==============================] - 7s 719us/step - loss: 0.3463 - acc: 0.8981 - sparse_top_k_categorical_accuracy: 0.9934 - val_loss: 0.2818 - val_acc: 0.9284 - val_sparse_top_k_categorical_accuracy: 0.9889\n",
      "Epoch 15/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.3028 - acc: 0.9095 - sparse_top_k_categorical_accuracy: 0.9937 - val_loss: 0.3298 - val_acc: 0.9067 - val_sparse_top_k_categorical_accuracy: 0.9909\n",
      "Epoch 16/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.2570 - acc: 0.9234 - sparse_top_k_categorical_accuracy: 0.9962 - val_loss: 0.6482 - val_acc: 0.8018 - val_sparse_top_k_categorical_accuracy: 0.9652\n",
      "Epoch 17/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.2186 - acc: 0.9342 - sparse_top_k_categorical_accuracy: 0.9970 - val_loss: 0.7599 - val_acc: 0.7806 - val_sparse_top_k_categorical_accuracy: 0.9566\n",
      "Epoch 18/150\n",
      "9253/9253 [==============================] - 7s 717us/step - loss: 0.1924 - acc: 0.9441 - sparse_top_k_categorical_accuracy: 0.9978 - val_loss: 0.4449 - val_acc: 0.8709 - val_sparse_top_k_categorical_accuracy: 0.9854\n",
      "Epoch 19/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.1750 - acc: 0.9475 - sparse_top_k_categorical_accuracy: 0.9984 - val_loss: 0.4268 - val_acc: 0.8674 - val_sparse_top_k_categorical_accuracy: 0.9839\n",
      "Epoch 20/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.1474 - acc: 0.9559 - sparse_top_k_categorical_accuracy: 0.9988 - val_loss: 0.6527 - val_acc: 0.8195 - val_sparse_top_k_categorical_accuracy: 0.9697\n",
      "Epoch 21/150\n",
      "9253/9253 [==============================] - 7s 719us/step - loss: 0.1436 - acc: 0.9580 - sparse_top_k_categorical_accuracy: 0.9985 - val_loss: 0.2559 - val_acc: 0.9254 - val_sparse_top_k_categorical_accuracy: 0.9924\n",
      "Epoch 22/150\n",
      "9253/9253 [==============================] - 7s 719us/step - loss: 0.1261 - acc: 0.9631 - sparse_top_k_categorical_accuracy: 0.9991 - val_loss: 0.2642 - val_acc: 0.9213 - val_sparse_top_k_categorical_accuracy: 0.9919\n",
      "Epoch 23/150\n",
      "9253/9253 [==============================] - 7s 720us/step - loss: 0.1223 - acc: 0.9643 - sparse_top_k_categorical_accuracy: 0.9996 - val_loss: 0.4288 - val_acc: 0.8623 - val_sparse_top_k_categorical_accuracy: 0.9859\n",
      "Epoch 24/150\n",
      "9253/9253 [==============================] - 7s 719us/step - loss: 0.1088 - acc: 0.9682 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.1231 - val_acc: 0.9592 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 25/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.1014 - acc: 0.9704 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 0.2418 - val_acc: 0.9218 - val_sparse_top_k_categorical_accuracy: 0.9939\n",
      "Epoch 26/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0920 - acc: 0.9729 - sparse_top_k_categorical_accuracy: 0.9996 - val_loss: 0.1219 - val_acc: 0.9561 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 27/150\n",
      "9253/9253 [==============================] - 7s 718us/step - loss: 0.0953 - acc: 0.9713 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.1300 - val_acc: 0.9592 - val_sparse_top_k_categorical_accuracy: 0.9960\n",
      "Epoch 28/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0894 - acc: 0.9722 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.2327 - val_acc: 0.9259 - val_sparse_top_k_categorical_accuracy: 0.9914\n",
      "Epoch 29/150\n",
      "9253/9253 [==============================] - 7s 720us/step - loss: 0.0777 - acc: 0.9776 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.1265 - val_acc: 0.9627 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 30/150\n",
      "9253/9253 [==============================] - 7s 720us/step - loss: 0.0769 - acc: 0.9763 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 0.1124 - val_acc: 0.9647 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 31/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0725 - acc: 0.9769 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 0.3547 - val_acc: 0.8956 - val_sparse_top_k_categorical_accuracy: 0.9854\n",
      "Epoch 32/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0685 - acc: 0.9800 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.3354 - val_acc: 0.8931 - val_sparse_top_k_categorical_accuracy: 0.9889\n",
      "Epoch 33/150\n",
      "9253/9253 [==============================] - 7s 722us/step - loss: 0.0592 - acc: 0.9805 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.5843 - val_acc: 0.8245 - val_sparse_top_k_categorical_accuracy: 0.9808\n",
      "Epoch 34/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0588 - acc: 0.9824 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0977 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 35/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9253/9253 [==============================] - 7s 720us/step - loss: 0.0518 - acc: 0.9839 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0854 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 36/150\n",
      "9253/9253 [==============================] - 7s 720us/step - loss: 0.0562 - acc: 0.9831 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1264 - val_acc: 0.9597 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 37/150\n",
      "9253/9253 [==============================] - 7s 719us/step - loss: 0.0497 - acc: 0.9852 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1352 - val_acc: 0.9586 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 38/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0552 - acc: 0.9830 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1367 - val_acc: 0.9571 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 39/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0536 - acc: 0.9824 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0939 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 40/150\n",
      "9253/9253 [==============================] - 7s 722us/step - loss: 0.0479 - acc: 0.9841 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0937 - val_acc: 0.9702 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 41/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0424 - acc: 0.9879 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1123 - val_acc: 0.9612 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 42/150\n",
      "9253/9253 [==============================] - 7s 720us/step - loss: 0.0472 - acc: 0.9840 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0887 - val_acc: 0.9697 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 43/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0480 - acc: 0.9838 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.3370 - val_acc: 0.8906 - val_sparse_top_k_categorical_accuracy: 0.9899\n",
      "Epoch 44/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0469 - acc: 0.9849 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1038 - val_acc: 0.9667 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 45/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0391 - acc: 0.9865 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0806 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 46/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0423 - acc: 0.9856 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.5432 - val_acc: 0.8411 - val_sparse_top_k_categorical_accuracy: 0.9768\n",
      "Epoch 47/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0370 - acc: 0.9895 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1247 - val_acc: 0.9597 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 48/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0382 - acc: 0.9875 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0850 - val_acc: 0.9697 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 49/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0404 - acc: 0.9867 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0885 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 50/150\n",
      "9253/9253 [==============================] - 7s 721us/step - loss: 0.0345 - acc: 0.9889 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0798 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 51/150\n",
      "9253/9253 [==============================] - 7s 722us/step - loss: 0.0355 - acc: 0.9888 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0748 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 52/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0375 - acc: 0.9862 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0778 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 53/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0372 - acc: 0.9878 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0779 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 54/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0314 - acc: 0.9890 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0787 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 55/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0300 - acc: 0.9897 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0843 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 56/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0336 - acc: 0.9888 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1020 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 57/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0333 - acc: 0.9881 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0843 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 58/150\n",
      "9253/9253 [==============================] - 7s 722us/step - loss: 0.0296 - acc: 0.9899 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0840 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 59/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0292 - acc: 0.9893 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0894 - val_acc: 0.9697 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 60/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0300 - acc: 0.9898 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0958 - val_acc: 0.9677 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 61/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0295 - acc: 0.9894 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0985 - val_acc: 0.9692 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 62/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0321 - acc: 0.9875 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1266 - val_acc: 0.9602 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 63/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0268 - acc: 0.9895 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1057 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 64/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0257 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0796 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 65/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0259 - acc: 0.9903 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1582 - val_acc: 0.9506 - val_sparse_top_k_categorical_accuracy: 0.9960\n",
      "Epoch 66/150\n",
      "9253/9253 [==============================] - 7s 719us/step - loss: 0.0295 - acc: 0.9901 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0812 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 67/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0271 - acc: 0.9894 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0764 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 68/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0292 - acc: 0.9895 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0743 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 69/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0260 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1107 - val_acc: 0.9632 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 70/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0255 - acc: 0.9914 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0715 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0238 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0667 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 72/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0264 - acc: 0.9902 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1090 - val_acc: 0.9672 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 73/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0258 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1236 - val_acc: 0.9592 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 74/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0255 - acc: 0.9896 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0755 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 75/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0242 - acc: 0.9906 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1017 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 76/150\n",
      "9253/9253 [==============================] - 7s 727us/step - loss: 0.0242 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0667 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 77/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0221 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0785 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 78/150\n",
      "9253/9253 [==============================] - 7s 727us/step - loss: 0.0256 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0943 - val_acc: 0.9672 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 79/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0238 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1563 - val_acc: 0.9551 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 80/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0270 - acc: 0.9891 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0738 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 81/150\n",
      "9253/9253 [==============================] - 7s 727us/step - loss: 0.0216 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0696 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 82/150\n",
      "9253/9253 [==============================] - 7s 728us/step - loss: 0.0198 - acc: 0.9927 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0718 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 83/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0226 - acc: 0.9919 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0723 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 84/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0228 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0800 - val_acc: 0.9718 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 85/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0198 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0658 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 86/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0224 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0844 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 87/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0232 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0911 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 88/150\n",
      "9253/9253 [==============================] - 7s 728us/step - loss: 0.0169 - acc: 0.9933 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0684 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 89/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0213 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0830 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 90/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0223 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0745 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 91/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0196 - acc: 0.9919 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1229 - val_acc: 0.9647 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 92/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0226 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1468 - val_acc: 0.9531 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 93/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0214 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0883 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 94/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0192 - acc: 0.9923 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0810 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 95/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0195 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0727 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 96/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0207 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0780 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 97/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0206 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0806 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 98/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0187 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0754 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 99/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0192 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0761 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 100/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0184 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0667 - val_acc: 0.9803 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 101/150\n",
      "9253/9253 [==============================] - 7s 722us/step - loss: 0.0176 - acc: 0.9931 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0663 - val_acc: 0.9778 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 102/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0192 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1620 - val_acc: 0.9481 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 103/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0207 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0750 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 104/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0205 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0761 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 105/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0184 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0743 - val_acc: 0.9773 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0191 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0703 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 107/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0196 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0679 - val_acc: 0.9773 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 108/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0196 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0856 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 109/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0185 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0834 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 110/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0190 - acc: 0.9918 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0828 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 111/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0194 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0716 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 112/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0161 - acc: 0.9942 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0691 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 113/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0163 - acc: 0.9930 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0723 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9995\n",
      "Epoch 114/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0162 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0900 - val_acc: 0.9702 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 115/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0181 - acc: 0.9932 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0831 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 116/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0169 - acc: 0.9927 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0668 - val_acc: 0.9773 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 117/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0170 - acc: 0.9934 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0808 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 118/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0171 - acc: 0.9925 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0670 - val_acc: 0.9788 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 119/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0175 - acc: 0.9925 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0781 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 120/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0188 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0658 - val_acc: 0.9783 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 121/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0148 - acc: 0.9927 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0682 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 122/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0165 - acc: 0.9932 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0748 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 123/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0173 - acc: 0.9936 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0755 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 124/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0160 - acc: 0.9933 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0758 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 125/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0147 - acc: 0.9938 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0668 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 126/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0170 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0654 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 127/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0147 - acc: 0.9939 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0714 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 128/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0150 - acc: 0.9935 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0725 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 129/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0151 - acc: 0.9932 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0742 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 130/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0158 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.3517 - val_acc: 0.9032 - val_sparse_top_k_categorical_accuracy: 0.9909\n",
      "Epoch 131/150\n",
      "9253/9253 [==============================] - 7s 729us/step - loss: 0.0168 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0681 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 132/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0161 - acc: 0.9927 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0759 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 133/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0176 - acc: 0.9932 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0796 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 134/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0164 - acc: 0.9923 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0744 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 135/150\n",
      "9253/9253 [==============================] - 7s 727us/step - loss: 0.0156 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0762 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 136/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0154 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0682 - val_acc: 0.9783 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 137/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0166 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0751 - val_acc: 0.9718 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 138/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0188 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0724 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 139/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0163 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0705 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 140/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0146 - acc: 0.9935 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0670 - val_acc: 0.9778 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0141 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0686 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 142/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0169 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0675 - val_acc: 0.9773 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 143/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0159 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0873 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 144/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0144 - acc: 0.9931 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0702 - val_acc: 0.9783 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 145/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0159 - acc: 0.9936 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0808 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 146/150\n",
      "9253/9253 [==============================] - 7s 725us/step - loss: 0.0153 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0635 - val_acc: 0.9773 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 147/150\n",
      "9253/9253 [==============================] - 7s 724us/step - loss: 0.0148 - acc: 0.9931 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0655 - val_acc: 0.9793 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 148/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0157 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0718 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 149/150\n",
      "9253/9253 [==============================] - 7s 723us/step - loss: 0.0152 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0720 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 150/150\n",
      "9253/9253 [==============================] - 7s 726us/step - loss: 0.0192 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0686 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "#model 1\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='SGD', metrics=['accuracy','sparse_top_k_categorical_accuracy'])\n",
    "history=model.fit(X_train,y_train, batch_size=16, epochs=150, validation_data=(X_val, y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 9253 samples, validate on 1983 samples\n",
      "Epoch 1/150\n",
      "9253/9253 [==============================] - 10s 1ms/step - loss: 4.6796 - acc: 0.0327 - sparse_top_k_categorical_accuracy: 0.1142 - val_loss: 4.7234 - val_acc: 0.0323 - val_sparse_top_k_categorical_accuracy: 0.0978\n",
      "Epoch 2/150\n",
      "9253/9253 [==============================] - 5s 558us/step - loss: 3.9945 - acc: 0.1138 - sparse_top_k_categorical_accuracy: 0.3110 - val_loss: 3.6434 - val_acc: 0.1427 - val_sparse_top_k_categorical_accuracy: 0.4075\n",
      "Epoch 3/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 3.1674 - acc: 0.2319 - sparse_top_k_categorical_accuracy: 0.5376 - val_loss: 2.4745 - val_acc: 0.4165 - val_sparse_top_k_categorical_accuracy: 0.7569\n",
      "Epoch 4/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 2.4309 - acc: 0.3756 - sparse_top_k_categorical_accuracy: 0.7038 - val_loss: 1.7648 - val_acc: 0.6082 - val_sparse_top_k_categorical_accuracy: 0.8719\n",
      "Epoch 5/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 1.8951 - acc: 0.4895 - sparse_top_k_categorical_accuracy: 0.8101 - val_loss: 1.4358 - val_acc: 0.6566 - val_sparse_top_k_categorical_accuracy: 0.9012\n",
      "Epoch 6/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 1.4981 - acc: 0.5900 - sparse_top_k_categorical_accuracy: 0.8808 - val_loss: 1.3905 - val_acc: 0.5986 - val_sparse_top_k_categorical_accuracy: 0.8971\n",
      "Epoch 7/150\n",
      "9253/9253 [==============================] - 6s 610us/step - loss: 1.1806 - acc: 0.6686 - sparse_top_k_categorical_accuracy: 0.9218 - val_loss: 0.8946 - val_acc: 0.7559 - val_sparse_top_k_categorical_accuracy: 0.9435\n",
      "Epoch 8/150\n",
      "9253/9253 [==============================] - 5s 590us/step - loss: 0.9297 - acc: 0.7332 - sparse_top_k_categorical_accuracy: 0.9522 - val_loss: 0.6652 - val_acc: 0.8371 - val_sparse_top_k_categorical_accuracy: 0.9713\n",
      "Epoch 9/150\n",
      "9253/9253 [==============================] - 6s 601us/step - loss: 0.7454 - acc: 0.7877 - sparse_top_k_categorical_accuracy: 0.9664 - val_loss: 0.4469 - val_acc: 0.8886 - val_sparse_top_k_categorical_accuracy: 0.9839\n",
      "Epoch 10/150\n",
      "9253/9253 [==============================] - 5s 591us/step - loss: 0.6007 - acc: 0.8276 - sparse_top_k_categorical_accuracy: 0.9778 - val_loss: 0.4043 - val_acc: 0.9037 - val_sparse_top_k_categorical_accuracy: 0.9884\n",
      "Epoch 11/150\n",
      "9253/9253 [==============================] - 5s 582us/step - loss: 0.4994 - acc: 0.8555 - sparse_top_k_categorical_accuracy: 0.9839 - val_loss: 0.3837 - val_acc: 0.9027 - val_sparse_top_k_categorical_accuracy: 0.9859\n",
      "Epoch 12/150\n",
      "9253/9253 [==============================] - 5s 564us/step - loss: 0.4086 - acc: 0.8833 - sparse_top_k_categorical_accuracy: 0.9906 - val_loss: 0.3426 - val_acc: 0.9133 - val_sparse_top_k_categorical_accuracy: 0.9914\n",
      "Epoch 13/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 0.3281 - acc: 0.9041 - sparse_top_k_categorical_accuracy: 0.9915 - val_loss: 0.3229 - val_acc: 0.9107 - val_sparse_top_k_categorical_accuracy: 0.9879\n",
      "Epoch 14/150\n",
      "9253/9253 [==============================] - 5s 560us/step - loss: 0.2850 - acc: 0.9192 - sparse_top_k_categorical_accuracy: 0.9946 - val_loss: 0.2695 - val_acc: 0.9274 - val_sparse_top_k_categorical_accuracy: 0.9924\n",
      "Epoch 15/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.2324 - acc: 0.9338 - sparse_top_k_categorical_accuracy: 0.9972 - val_loss: 0.2151 - val_acc: 0.9420 - val_sparse_top_k_categorical_accuracy: 0.9950\n",
      "Epoch 16/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.2042 - acc: 0.9398 - sparse_top_k_categorical_accuracy: 0.9983 - val_loss: 0.1879 - val_acc: 0.9496 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 17/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.1801 - acc: 0.9459 - sparse_top_k_categorical_accuracy: 0.9981 - val_loss: 0.2331 - val_acc: 0.9269 - val_sparse_top_k_categorical_accuracy: 0.9960\n",
      "Epoch 18/150\n",
      "9253/9253 [==============================] - 5s 562us/step - loss: 0.1521 - acc: 0.9546 - sparse_top_k_categorical_accuracy: 0.9986 - val_loss: 0.2209 - val_acc: 0.9405 - val_sparse_top_k_categorical_accuracy: 0.9929\n",
      "Epoch 19/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.1393 - acc: 0.9609 - sparse_top_k_categorical_accuracy: 0.9991 - val_loss: 0.1620 - val_acc: 0.9511 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 20/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 0.1222 - acc: 0.9635 - sparse_top_k_categorical_accuracy: 0.9989 - val_loss: 0.1227 - val_acc: 0.9617 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 21/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 0.1116 - acc: 0.9662 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 0.1685 - val_acc: 0.9481 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 22/150\n",
      "9253/9253 [==============================] - 5s 560us/step - loss: 0.1023 - acc: 0.9678 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 0.1456 - val_acc: 0.9586 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 23/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 0.0927 - acc: 0.9737 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.1377 - val_acc: 0.9607 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 24/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0891 - acc: 0.9733 - sparse_top_k_categorical_accuracy: 0.9995 - val_loss: 0.1455 - val_acc: 0.9632 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 25/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.0790 - acc: 0.9778 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 0.1145 - val_acc: 0.9657 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 26/150\n",
      "9253/9253 [==============================] - 5s 562us/step - loss: 0.0732 - acc: 0.9762 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.1355 - val_acc: 0.9576 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 27/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 0.0680 - acc: 0.9807 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1114 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 28/150\n",
      "9253/9253 [==============================] - 5s 558us/step - loss: 0.0643 - acc: 0.9800 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1112 - val_acc: 0.9622 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 29/150\n",
      "9253/9253 [==============================] - 5s 562us/step - loss: 0.0637 - acc: 0.9777 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1042 - val_acc: 0.9672 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 30/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 0.0590 - acc: 0.9821 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 0.1210 - val_acc: 0.9592 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 31/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 0.0562 - acc: 0.9815 - sparse_top_k_categorical_accuracy: 0.9997 - val_loss: 0.1248 - val_acc: 0.9617 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 32/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0514 - acc: 0.9835 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1095 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 33/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0476 - acc: 0.9843 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1502 - val_acc: 0.9571 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 34/150\n",
      "9253/9253 [==============================] - 5s 552us/step - loss: 0.0451 - acc: 0.9851 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1182 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 35/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0437 - acc: 0.9856 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1119 - val_acc: 0.9677 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 36/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 0.0434 - acc: 0.9839 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1113 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 37/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0474 - acc: 0.9839 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1030 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 38/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0450 - acc: 0.9831 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1204 - val_acc: 0.9632 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 39/150\n",
      "9253/9253 [==============================] - 5s 554us/step - loss: 0.0362 - acc: 0.9879 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1417 - val_acc: 0.9597 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 40/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0377 - acc: 0.9875 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1282 - val_acc: 0.9617 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 41/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0374 - acc: 0.9883 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1672 - val_acc: 0.9516 - val_sparse_top_k_categorical_accuracy: 0.9945\n",
      "Epoch 42/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0389 - acc: 0.9868 - sparse_top_k_categorical_accuracy: 0.9998 - val_loss: 0.1013 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 43/150\n",
      "9253/9253 [==============================] - 5s 554us/step - loss: 0.0338 - acc: 0.9876 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0986 - val_acc: 0.9692 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 44/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0351 - acc: 0.9864 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1853 - val_acc: 0.9481 - val_sparse_top_k_categorical_accuracy: 0.9934\n",
      "Epoch 45/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0339 - acc: 0.9877 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1065 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 46/150\n",
      "9253/9253 [==============================] - 5s 558us/step - loss: 0.0349 - acc: 0.9883 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1079 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 47/150\n",
      "9253/9253 [==============================] - 5s 554us/step - loss: 0.0328 - acc: 0.9895 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1103 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 48/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0334 - acc: 0.9875 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0926 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 49/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0321 - acc: 0.9884 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.0953 - val_acc: 0.9697 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 50/150\n",
      "9253/9253 [==============================] - 5s 562us/step - loss: 0.0322 - acc: 0.9892 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1027 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 51/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0296 - acc: 0.9889 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1173 - val_acc: 0.9637 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 52/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0312 - acc: 0.9893 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1670 - val_acc: 0.9521 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 53/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0280 - acc: 0.9892 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1268 - val_acc: 0.9607 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 54/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0279 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1253 - val_acc: 0.9667 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 55/150\n",
      "9253/9253 [==============================] - 5s 558us/step - loss: 0.0295 - acc: 0.9897 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0925 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 56/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 0.0310 - acc: 0.9892 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2008 - val_acc: 0.9455 - val_sparse_top_k_categorical_accuracy: 0.9924\n",
      "Epoch 57/150\n",
      "9253/9253 [==============================] - 5s 563us/step - loss: 0.0298 - acc: 0.9896 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1837 - val_acc: 0.9516 - val_sparse_top_k_categorical_accuracy: 0.9934\n",
      "Epoch 58/150\n",
      "9253/9253 [==============================] - 5s 561us/step - loss: 0.0287 - acc: 0.9889 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0976 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 59/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0273 - acc: 0.9893 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1073 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 60/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 0.0261 - acc: 0.9902 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1242 - val_acc: 0.9692 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 61/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0255 - acc: 0.9899 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1192 - val_acc: 0.9662 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 62/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0243 - acc: 0.9899 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0979 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 63/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0297 - acc: 0.9891 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1480 - val_acc: 0.9612 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 64/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0265 - acc: 0.9902 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1475 - val_acc: 0.9622 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 65/150\n",
      "9253/9253 [==============================] - 5s 560us/step - loss: 0.0256 - acc: 0.9902 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1028 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 66/150\n",
      "9253/9253 [==============================] - 5s 560us/step - loss: 0.0259 - acc: 0.9893 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1445 - val_acc: 0.9607 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 67/150\n",
      "9253/9253 [==============================] - 5s 563us/step - loss: 0.0241 - acc: 0.9901 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1227 - val_acc: 0.9607 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 68/150\n",
      "9253/9253 [==============================] - 5s 560us/step - loss: 0.0233 - acc: 0.9908 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0966 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 69/150\n",
      "9253/9253 [==============================] - 5s 564us/step - loss: 0.0231 - acc: 0.9908 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1206 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 70/150\n",
      "9253/9253 [==============================] - 5s 566us/step - loss: 0.0271 - acc: 0.9878 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1248 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0224 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1203 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 72/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0245 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1263 - val_acc: 0.9672 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 73/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0227 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1090 - val_acc: 0.9702 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 74/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0226 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1475 - val_acc: 0.9597 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 75/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0247 - acc: 0.9906 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1371 - val_acc: 0.9647 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 76/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0235 - acc: 0.9906 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1219 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 77/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0227 - acc: 0.9906 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1593 - val_acc: 0.9586 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 78/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0272 - acc: 0.9907 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1008 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 79/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0206 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1015 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 80/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0196 - acc: 0.9919 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1615 - val_acc: 0.9597 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 81/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0228 - acc: 0.9896 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0916 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 82/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0205 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1094 - val_acc: 0.9702 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 83/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0204 - acc: 0.9919 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1376 - val_acc: 0.9677 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 84/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0220 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1176 - val_acc: 0.9702 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 85/150\n",
      "9253/9253 [==============================] - 5s 554us/step - loss: 0.0202 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1266 - val_acc: 0.9642 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 86/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0223 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1299 - val_acc: 0.9647 - val_sparse_top_k_categorical_accuracy: 0.9960\n",
      "Epoch 87/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0200 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0916 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 88/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0230 - acc: 0.9903 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2627 - val_acc: 0.9314 - val_sparse_top_k_categorical_accuracy: 0.9945\n",
      "Epoch 89/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0177 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1282 - val_acc: 0.9718 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 90/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0238 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1461 - val_acc: 0.9617 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 91/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0219 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1142 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 92/150\n",
      "9253/9253 [==============================] - 5s 558us/step - loss: 0.0224 - acc: 0.9901 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0995 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 93/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0234 - acc: 0.9909 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1228 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 94/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0221 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1075 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 95/150\n",
      "9253/9253 [==============================] - 5s 559us/step - loss: 0.0221 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0998 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 96/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0188 - acc: 0.9927 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1126 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 97/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0220 - acc: 0.9910 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1341 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 98/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0217 - acc: 0.9904 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0979 - val_acc: 0.9773 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 99/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0178 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2201 - val_acc: 0.9465 - val_sparse_top_k_categorical_accuracy: 0.9950\n",
      "Epoch 100/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0209 - acc: 0.9908 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0985 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 101/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0193 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2444 - val_acc: 0.9415 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 102/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0206 - acc: 0.9910 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1023 - val_acc: 0.9743 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 103/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0191 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1336 - val_acc: 0.9672 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 104/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0207 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1671 - val_acc: 0.9551 - val_sparse_top_k_categorical_accuracy: 0.9970\n",
      "Epoch 105/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0209 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1191 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 106/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0190 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1067 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 107/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0209 - acc: 0.9903 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1090 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 108/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0201 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1542 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 109/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0164 - acc: 0.9919 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1325 - val_acc: 0.9692 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 110/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0195 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1193 - val_acc: 0.9697 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 111/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0172 - acc: 0.9918 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1251 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 112/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0192 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1230 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 113/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0220 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1046 - val_acc: 0.9758 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 114/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0200 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1118 - val_acc: 0.9723 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 115/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0174 - acc: 0.9925 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1154 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 116/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0196 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1081 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 117/150\n",
      "9253/9253 [==============================] - 5s 562us/step - loss: 0.0177 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1577 - val_acc: 0.9607 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 118/150\n",
      "9253/9253 [==============================] - 5s 568us/step - loss: 0.0192 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1098 - val_acc: 0.9718 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 119/150\n",
      "9253/9253 [==============================] - 5s 569us/step - loss: 0.0198 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1438 - val_acc: 0.9667 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 120/150\n",
      "9253/9253 [==============================] - 5s 562us/step - loss: 0.0183 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 0.9999 - val_loss: 0.1341 - val_acc: 0.9702 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 121/150\n",
      "9253/9253 [==============================] - 5s 556us/step - loss: 0.0189 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1027 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 122/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0201 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1123 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 123/150\n",
      "9253/9253 [==============================] - 5s 565us/step - loss: 0.0212 - acc: 0.9907 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1322 - val_acc: 0.9682 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 124/150\n",
      "9253/9253 [==============================] - 5s 570us/step - loss: 0.0187 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1506 - val_acc: 0.9632 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 125/150\n",
      "9253/9253 [==============================] - 5s 567us/step - loss: 0.0212 - acc: 0.9912 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.0993 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 126/150\n",
      "9253/9253 [==============================] - 5s 566us/step - loss: 0.0195 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1108 - val_acc: 0.9713 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 127/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.0202 - acc: 0.9905 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1370 - val_acc: 0.9677 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 128/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0191 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1843 - val_acc: 0.9581 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 129/150\n",
      "9253/9253 [==============================] - 5s 553us/step - loss: 0.0179 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1341 - val_acc: 0.9728 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 130/150\n",
      "9253/9253 [==============================] - 5s 555us/step - loss: 0.0181 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2291 - val_acc: 0.9531 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 131/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.0171 - acc: 0.9930 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2653 - val_acc: 0.9400 - val_sparse_top_k_categorical_accuracy: 0.9955\n",
      "Epoch 132/150\n",
      "9253/9253 [==============================] - 5s 557us/step - loss: 0.0195 - acc: 0.9914 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1075 - val_acc: 0.9763 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 133/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.0161 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1277 - val_acc: 0.9687 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 134/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0160 - acc: 0.9927 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1424 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 135/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0187 - acc: 0.9911 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1313 - val_acc: 0.9692 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 136/150\n",
      "9253/9253 [==============================] - 5s 551us/step - loss: 0.0200 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.2079 - val_acc: 0.9581 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 137/150\n",
      "9253/9253 [==============================] - 5s 548us/step - loss: 0.0183 - acc: 0.9929 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1170 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 138/150\n",
      "9253/9253 [==============================] - 5s 546us/step - loss: 0.0189 - acc: 0.9923 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1309 - val_acc: 0.9748 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 139/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0204 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1586 - val_acc: 0.9652 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 140/150\n",
      "9253/9253 [==============================] - 5s 549us/step - loss: 0.0170 - acc: 0.9930 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1438 - val_acc: 0.9667 - val_sparse_top_k_categorical_accuracy: 0.9965\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0168 - acc: 0.9921 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1174 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 142/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0170 - acc: 0.9918 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1177 - val_acc: 0.9718 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 143/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0168 - acc: 0.9920 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1140 - val_acc: 0.9753 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 144/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0176 - acc: 0.9923 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1096 - val_acc: 0.9733 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 145/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0172 - acc: 0.9917 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1149 - val_acc: 0.9788 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 146/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0166 - acc: 0.9930 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1401 - val_acc: 0.9692 - val_sparse_top_k_categorical_accuracy: 0.9985\n",
      "Epoch 147/150\n",
      "9253/9253 [==============================] - 5s 549us/step - loss: 0.0171 - acc: 0.9922 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1003 - val_acc: 0.9768 - val_sparse_top_k_categorical_accuracy: 0.9975\n",
      "Epoch 148/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0168 - acc: 0.9915 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1269 - val_acc: 0.9738 - val_sparse_top_k_categorical_accuracy: 0.9990\n",
      "Epoch 149/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0168 - acc: 0.9916 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1044 - val_acc: 0.9783 - val_sparse_top_k_categorical_accuracy: 0.9980\n",
      "Epoch 150/150\n",
      "9253/9253 [==============================] - 5s 550us/step - loss: 0.0184 - acc: 0.9924 - sparse_top_k_categorical_accuracy: 1.0000 - val_loss: 0.1245 - val_acc: 0.9708 - val_sparse_top_k_categorical_accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "#model 2\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy','sparse_top_k_categorical_accuracy'])\n",
    "history=model.fit(X_train,y_train, batch_size=32, epochs=150, validation_data=(X_val, y_val) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_sparse_top_k_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>sparse_top_k_categorical_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.063533</td>\n",
       "      <td>0.977307</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.065490</td>\n",
       "      <td>0.979324</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>0.993083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.975290</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.992219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.071966</td>\n",
       "      <td>0.975290</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>0.992219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.068629</td>\n",
       "      <td>0.974786</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>0.991570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     val_loss   val_acc  val_sparse_top_k_categorical_accuracy      loss  \\\n",
       "145  0.063533  0.977307                               0.998991  0.015334   \n",
       "146  0.065490  0.979324                               0.998487  0.014834   \n",
       "147  0.071761  0.975290                               0.998991  0.015745   \n",
       "148  0.071966  0.975290                               0.998991  0.015159   \n",
       "149  0.068629  0.974786                               0.998991  0.019177   \n",
       "\n",
       "          acc  sparse_top_k_categorical_accuracy  epoch  \n",
       "145  0.992867                                1.0    145  \n",
       "146  0.993083                                1.0    146  \n",
       "147  0.992219                                1.0    147  \n",
       "148  0.992219                                1.0    148  \n",
       "149  0.991570                                1.0    149  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07355537263918865 / Test accuracy: 0.9737771054259227\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X_tes, y_tes, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_tes)\n",
    "y_pred  = y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[32  0  0 ...  0  0  0]\n",
      " [ 0 37  0 ...  0  0  0]\n",
      " [ 0  0 34 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 40  0  0]\n",
      " [ 0  0  0 ...  0 35  0]\n",
      " [ 0  0  0 ...  0  0 31]]\n",
      "\n",
      "Accuracy: 0.97378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_tes, y_pred )\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.5f}\\n'.format(accuracy_score(y_tes, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.97378\n",
      "Micro Recall: 0.97378\n",
      "Micro F1-score: 0.97378\n",
      "\n",
      "Macro Precision: 0.97369\n",
      "Macro Recall: 0.97378\n",
      "Macro F1-score: 0.97320\n",
      "\n",
      "Weighted Precision: 0.97504\n",
      "Weighted Recall: 0.97378\n",
      "Weighted F1-score: 0.97387\n"
     ]
    }
   ],
   "source": [
    "print('Micro Precision: {:.5f}'.format(precision_score(y_tes, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.5f}'.format(recall_score(y_tes, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.5f}\\n'.format(f1_score(y_tes, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.5f}'.format(precision_score(y_tes, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.5f}'.format(recall_score(y_tes, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.5f}\\n'.format(f1_score(y_tes, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.5f}'.format(precision_score(y_tes, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.5f}'.format(recall_score(y_tes, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.5f}'.format(f1_score(y_tes, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      0.97      0.99        38\n",
      "           2       0.97      0.94      0.96        36\n",
      "           3       1.00      1.00      1.00        32\n",
      "           4       0.93      0.96      0.94        26\n",
      "           5       1.00      1.00      1.00        28\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        38\n",
      "           8       1.00      0.92      0.96        25\n",
      "           9       1.00      1.00      1.00        37\n",
      "          10       1.00      0.97      0.99        34\n",
      "          11       1.00      1.00      1.00        30\n",
      "          12       0.66      0.49      0.56        43\n",
      "          13       0.42      0.59      0.49        29\n",
      "          14       0.96      1.00      0.98        24\n",
      "          15       1.00      1.00      1.00        29\n",
      "          16       0.91      1.00      0.95        31\n",
      "          17       1.00      1.00      1.00        30\n",
      "          18       0.96      1.00      0.98        22\n",
      "          19       1.00      1.00      1.00        39\n",
      "          20       1.00      1.00      1.00        34\n",
      "          21       0.97      0.95      0.96        37\n",
      "          22       0.96      0.96      0.96        24\n",
      "          23       1.00      1.00      1.00        21\n",
      "          24       1.00      0.96      0.98        26\n",
      "          25       1.00      1.00      1.00        37\n",
      "          26       0.97      1.00      0.98        30\n",
      "          27       1.00      1.00      1.00        36\n",
      "          28       1.00      1.00      1.00        27\n",
      "          29       1.00      1.00      1.00        33\n",
      "          30       0.97      0.94      0.95        31\n",
      "          31       0.62      0.54      0.58        28\n",
      "          32       0.55      0.64      0.59        25\n",
      "          33       1.00      0.96      0.98        27\n",
      "          34       1.00      0.94      0.97        33\n",
      "          35       0.95      1.00      0.98        40\n",
      "          36       1.00      0.93      0.96        28\n",
      "          37       1.00      1.00      1.00        27\n",
      "          38       1.00      1.00      1.00        34\n",
      "          39       0.97      1.00      0.98        29\n",
      "          40       0.96      1.00      0.98        23\n",
      "          41       0.95      1.00      0.97        39\n",
      "          42       1.00      1.00      1.00        36\n",
      "          43       1.00      1.00      1.00        34\n",
      "          44       0.96      1.00      0.98        27\n",
      "          45       0.97      0.97      0.97        36\n",
      "          46       0.97      1.00      0.99        37\n",
      "          47       1.00      0.96      0.98        23\n",
      "          48       1.00      1.00      1.00        34\n",
      "          49       0.93      0.93      0.93        29\n",
      "          50       1.00      1.00      1.00        28\n",
      "          51       1.00      0.88      0.94        33\n",
      "          52       1.00      1.00      1.00        28\n",
      "          53       1.00      0.97      0.99        37\n",
      "          54       1.00      1.00      1.00        29\n",
      "          55       1.00      1.00      1.00        37\n",
      "          56       1.00      0.97      0.98        30\n",
      "          57       1.00      0.97      0.99        38\n",
      "          58       1.00      1.00      1.00        29\n",
      "          59       1.00      1.00      1.00        31\n",
      "          60       1.00      1.00      1.00        25\n",
      "          61       0.97      1.00      0.98        32\n",
      "          62       0.96      1.00      0.98        23\n",
      "          63       1.00      1.00      1.00        33\n",
      "          64       0.97      1.00      0.98        32\n",
      "          65       1.00      1.00      1.00        36\n",
      "          66       0.96      1.00      0.98        27\n",
      "          67       1.00      1.00      1.00        24\n",
      "          68       1.00      0.97      0.99        36\n",
      "          69       1.00      1.00      1.00        31\n",
      "          70       1.00      1.00      1.00        31\n",
      "          71       1.00      1.00      1.00        32\n",
      "          72       1.00      1.00      1.00        32\n",
      "          73       1.00      0.91      0.96        35\n",
      "          74       1.00      1.00      1.00        33\n",
      "          75       0.97      1.00      0.98        31\n",
      "          76       1.00      1.00      1.00        34\n",
      "          77       0.96      1.00      0.98        27\n",
      "          78       1.00      1.00      1.00        36\n",
      "          79       0.93      0.96      0.95        27\n",
      "          80       0.97      1.00      0.98        29\n",
      "          81       0.97      1.00      0.99        37\n",
      "          82       1.00      1.00      1.00        35\n",
      "          83       0.86      1.00      0.93        32\n",
      "          84       1.00      1.00      1.00        39\n",
      "          85       1.00      1.00      1.00        24\n",
      "          86       1.00      1.00      1.00        40\n",
      "          87       1.00      0.97      0.99        35\n",
      "          88       1.00      1.00      1.00        31\n",
      "          89       1.00      1.00      1.00        43\n",
      "          90       0.97      1.00      0.99        36\n",
      "          91       1.00      1.00      1.00        32\n",
      "          92       1.00      1.00      1.00        40\n",
      "          93       1.00      0.97      0.98        33\n",
      "          94       0.97      1.00      0.98        28\n",
      "          95       1.00      0.91      0.95        34\n",
      "          96       1.00      1.00      1.00        28\n",
      "          97       1.00      1.00      1.00        29\n",
      "          98       1.00      0.97      0.99        36\n",
      "          99       0.89      1.00      0.94        24\n",
      "         100       1.00      1.00      1.00        21\n",
      "         101       1.00      1.00      1.00        38\n",
      "         102       1.00      1.00      1.00        33\n",
      "         103       1.00      0.97      0.98        30\n",
      "         104       1.00      1.00      1.00        33\n",
      "         105       0.97      1.00      0.99        39\n",
      "         106       1.00      1.00      1.00        40\n",
      "         107       1.00      1.00      1.00        33\n",
      "         108       1.00      0.97      0.99        40\n",
      "         109       1.00      1.00      1.00        33\n",
      "         110       1.00      1.00      1.00        26\n",
      "         111       0.95      0.97      0.96        36\n",
      "         112       1.00      1.00      1.00        36\n",
      "         113       1.00      1.00      1.00        30\n",
      "         114       1.00      1.00      1.00        34\n",
      "         115       1.00      0.94      0.97        35\n",
      "         116       1.00      1.00      1.00        30\n",
      "         117       1.00      1.00      1.00        28\n",
      "         118       0.97      0.94      0.95        33\n",
      "         119       0.97      1.00      0.99        37\n",
      "         120       1.00      1.00      1.00        28\n",
      "         121       1.00      1.00      1.00        40\n",
      "         122       1.00      1.00      1.00        35\n",
      "         123       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           0.97      3966\n",
      "   macro avg       0.97      0.97      0.97      3966\n",
      "weighted avg       0.98      0.97      0.97      3966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_tes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_0a.pickle\",\"rb\")\n",
    "Xa = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_0a.pickle\",\"rb\")\n",
    "ya = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "Xa = Xa/255.0\n",
    "\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1207, 120, 120, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa= Xa.reshape(Xa.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "Xa_train, Xa_test, ya_train, ya_test = train_test_split(Xa, ya, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12795931738633107 / Test accuracy: 0.976802823553167\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score0 = model.evaluate( Xa_test, ya_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = model.predict(Xa_test)\n",
    "y_pred0  = y_pred0.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "\n",
      "Accuracy: 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(ya_test, y_pred0 )\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(ya_test, y_pred0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.96\n",
      "Micro Recall: 0.96\n",
      "Micro F1-score: 0.96\n",
      "\n",
      "Macro Precision: 0.96\n",
      "Macro Recall: 0.97\n",
      "Macro F1-score: 0.96\n",
      "\n",
      "Weighted Precision: 0.97\n",
      "Weighted Recall: 0.96\n",
      "Weighted F1-score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Micro Precision: {:.2f}'.format(precision_score(ya_test, y_pred0, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(ya_test, y_pred0, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(ya_test, y_pred0, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(ya_test, y_pred0, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(ya_test, y_pred0, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(ya_test, y_pred0, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(ya_test, y_pred0, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(ya_test, y_pred0, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(ya_test, y_pred0, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      0.62      0.77         8\n",
      "          12       1.00      0.25      0.40         4\n",
      "          13       0.40      1.00      0.57         2\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.56      1.00      0.71         5\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       1.00      1.00      1.00         3\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         4\n",
      "          22       1.00      1.00      1.00         5\n",
      "          23       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         4\n",
      "          27       1.00      1.00      1.00         1\n",
      "          29       1.00      1.00      1.00         4\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         4\n",
      "          32       1.00      1.00      1.00         2\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       1.00      1.00      1.00         5\n",
      "          35       1.00      1.00      1.00         2\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         3\n",
      "          38       1.00      1.00      1.00         5\n",
      "          39       1.00      1.00      1.00         4\n",
      "          40       1.00      1.00      1.00         4\n",
      "          41       0.50      1.00      0.67         1\n",
      "          42       1.00      1.00      1.00         5\n",
      "          43       1.00      1.00      1.00         4\n",
      "          44       1.00      1.00      1.00         2\n",
      "          45       1.00      1.00      1.00         6\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         4\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         3\n",
      "          51       1.00      1.00      1.00         4\n",
      "          52       1.00      1.00      1.00         1\n",
      "          53       1.00      1.00      1.00         5\n",
      "          54       1.00      1.00      1.00         4\n",
      "          55       1.00      1.00      1.00         1\n",
      "          56       1.00      1.00      1.00         4\n",
      "          57       1.00      1.00      1.00         1\n",
      "          58       1.00      1.00      1.00         3\n",
      "          59       1.00      1.00      1.00         1\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      1.00      1.00         2\n",
      "          63       1.00      1.00      1.00         4\n",
      "          64       1.00      1.00      1.00         3\n",
      "          65       1.00      1.00      1.00         2\n",
      "          66       1.00      1.00      1.00         1\n",
      "          67       1.00      1.00      1.00         2\n",
      "          68       1.00      1.00      1.00         1\n",
      "          69       1.00      1.00      1.00         4\n",
      "          70       1.00      1.00      1.00         3\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         5\n",
      "          73       1.00      0.80      0.89         5\n",
      "          74       1.00      1.00      1.00         3\n",
      "          75       1.00      1.00      1.00         1\n",
      "          76       1.00      1.00      1.00         4\n",
      "          77       1.00      1.00      1.00         2\n",
      "          78       0.50      1.00      0.67         2\n",
      "          79       0.00      0.00      0.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      1.00      1.00         2\n",
      "          83       1.00      1.00      1.00         4\n",
      "          84       1.00      1.00      1.00         4\n",
      "          85       1.00      1.00      1.00         3\n",
      "          86       1.00      1.00      1.00         2\n",
      "          87       1.00      1.00      1.00         2\n",
      "          88       1.00      1.00      1.00         3\n",
      "          89       1.00      1.00      1.00         4\n",
      "          90       1.00      1.00      1.00         3\n",
      "          91       1.00      1.00      1.00         4\n",
      "          92       1.00      1.00      1.00         4\n",
      "          93       1.00      1.00      1.00         6\n",
      "          94       1.00      1.00      1.00         4\n",
      "          95       1.00      1.00      1.00         4\n",
      "          96       1.00      1.00      1.00         4\n",
      "          97       1.00      1.00      1.00         2\n",
      "          99       1.00      1.00      1.00         3\n",
      "         100       1.00      1.00      1.00         1\n",
      "         101       1.00      1.00      1.00         6\n",
      "         102       1.00      1.00      1.00         2\n",
      "         103       1.00      1.00      1.00         3\n",
      "         104       1.00      1.00      1.00         3\n",
      "         105       1.00      1.00      1.00         5\n",
      "         106       1.00      1.00      1.00         5\n",
      "         107       1.00      1.00      1.00         3\n",
      "         108       1.00      1.00      1.00         2\n",
      "         109       1.00      1.00      1.00         3\n",
      "         110       1.00      1.00      1.00         1\n",
      "         111       0.25      1.00      0.40         1\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       1.00      1.00      1.00         4\n",
      "         114       1.00      1.00      1.00         2\n",
      "         115       1.00      1.00      1.00         3\n",
      "         116       1.00      1.00      1.00         4\n",
      "         117       1.00      1.00      1.00         5\n",
      "         118       1.00      1.00      1.00         2\n",
      "         119       1.00      1.00      1.00         3\n",
      "         120       1.00      1.00      1.00         3\n",
      "         121       1.00      1.00      1.00         2\n",
      "         122       1.00      1.00      1.00         3\n",
      "         123       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.96       363\n",
      "   macro avg       0.96      0.97      0.96       363\n",
      "weighted avg       0.97      0.96      0.96       363\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\Anaconda3\\envs\\Titanium\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(ya_test, y_pred0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_18a.pickle\",\"rb\")\n",
    "X18 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_18a.pickle\",\"rb\")\n",
    "y18 = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X18 = X18/255.0\n",
    "\n",
    "y18=np.array(y18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X18= X18.reshape(X18.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X18_train, X18_test, y18_train, y18_test = train_test_split(X18, y18, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.004058114788712077 / Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X18_test, y18_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred18 = model.predict( X18_test)\n",
    "y_pred18 = y_pred18.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 6 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y18_test,y_pred18)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y18_test, y_pred18)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_36a.pickle\",\"rb\")\n",
    "X36 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_36a.pickle\",\"rb\")\n",
    "y36 = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X36 = X36/255.0\n",
    "\n",
    "y36=np.array(y36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X36= X36.reshape(X36.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X36_train, X36_test, y36_train, y36_test = train_test_split(X36, y36, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.01636376516236886 / Test accuracy: 0.9917355371900827\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X36_test, y36_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred36 = model.predict( X36_test)\n",
    "y_pred36 = y_pred36.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y36_test, y_pred36)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y36_test, y_pred36)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_54a.pickle\",\"rb\")\n",
    "X54 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_54a.pickle\",\"rb\")\n",
    "y54 = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X54 = X54/255.0\n",
    "\n",
    "y54=np.array(y54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X54= X54.reshape(X54.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X54_train, X54_test, y54_train, y54_test = train_test_split(X54, y54, test_size=0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.047857657824125176 / Test accuracy: 0.9944598337950139\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X54_test, y54_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred54 = model.predict( X54_test)\n",
    "y_pred54 = y_pred54.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[5 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 5 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y54_test, y_pred54)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y54_test, y_pred54)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_72a.pickle\",\"rb\")\n",
    "X72 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_72a.pickle\",\"rb\")\n",
    "y72 = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X72 = X72/255.0\n",
    "\n",
    "y72=np.array(y72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X72= X72.reshape(X72.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X72_train, X72_test, y72_train, y72_test = train_test_split(X72, y72, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02338896364947313 / Test accuracy: 0.9944903581267218\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X72_test, y72_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred72 = model.predict( X72_test)\n",
    "y_pred72 = y_pred72.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 5 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 6 0 0]\n",
      " [0 0 0 ... 0 6 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y72_test,y_pred72)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y72_test,y_pred72)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_90a.pickle\",\"rb\")\n",
    "X90 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_90a.pickle\",\"rb\")\n",
    "y90 = pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X90 = X90/255.0\n",
    "\n",
    "y90=np.array(y90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X90= X90.reshape(X90.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X90_train, X90_test, y90_train, y90_test = train_test_split(X90, y90, test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07911341942630962 / Test accuracy: 0.9862258953168044\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X90_test, y90_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred90 = model.predict( X90_test)\n",
    "y_pred90 = y_pred90.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[1 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y90_test, y_pred90)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y90_test, y_pred90)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_108a.pickle\",\"rb\")\n",
    "X108 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_108a.pickle\",\"rb\")\n",
    "y108= pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X108 = X108/255.0\n",
    "\n",
    "y108=np.array(y108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X108= X108.reshape(X108.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X108_train, X108_test, y108_train, y108_test = train_test_split(X108, y108, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5002295376403575 / Test accuracy: 0.9539295396184534\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X108_test, y108_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred108 = model.predict( X108_test)\n",
    "y_pred108 = y_pred108.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 6 0 ... 0 0 0]\n",
      " [0 0 2 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 4 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 5]]\n",
      "\n",
      "Accuracy: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y108_test, y_pred108)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y108_test, y_pred108)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_126a.pickle\",\"rb\")\n",
    "X126 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_126a.pickle\",\"rb\")\n",
    "y126= pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X126 = X126/255.0\n",
    "\n",
    "y126=np.array(y126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X126= X126.reshape(X126.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X126_train, X126_test, y126_train, y126_test = train_test_split(X126, y126, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.017074565112691037 / Test accuracy: 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X126_test, y126_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred126 = model.predict( X126_test)\n",
    "y_pred126 = y_pred126.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 5 0]\n",
      " [0 0 0 ... 0 0 5]]\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y126_test, y_pred126)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y126_test, y_pred126)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_144a.pickle\",\"rb\")\n",
    "X144 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_144a.pickle\",\"rb\")\n",
    "y144= pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X144 = X144/255.0\n",
    "\n",
    "y144=np.array(y144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X144= X144.reshape(X144.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X144_train, X144_test, y144_train, y144_test = train_test_split(X144, y144, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1007831640367739 / Test accuracy: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X144_test, y144_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred144 = model.predict( X144_test)\n",
    "y_pred144 = y_pred144.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 3]]\n",
      "\n",
      "Accuracy: 0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y144_test, y_pred144 )\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y144_test, y_pred144)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_162a.pickle\",\"rb\")\n",
    "X162 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_162a.pickle\",\"rb\")\n",
    "y162= pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X162 = X162/255.0\n",
    "\n",
    "y162=np.array(y162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X162= X162.reshape(X162.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X162_train, X162_test, y162_train, y162_test = train_test_split(X162, y162, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.012520021697676704 / Test accuracy: 0.9916201117318436\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X162_test, y162_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 3 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 6 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "\n",
      "Accuracy: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict( X18_test)\n",
    "y_classes = y_pred.argmax(axis=-1)\n",
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y18_test, y_classes)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y18_test, y_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCR For Angle 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X_180a.pickle\",\"rb\")\n",
    "X180 = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y_180a.pickle\",\"rb\")\n",
    "y180= pickle.load(pickle_in)\n",
    "num_classes=124\n",
    "X180 = X180/255.0\n",
    "\n",
    "y180=np.array(y180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X180= X180.reshape(X180.shape[0], 30, 30, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split again, and we should see the same split\n",
    "X180_train, X180_test, y180_train, y180_test = train_test_split(X180, y180, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2506715303101033 / Test accuracy: 0.9697802197802198\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate( X180_test, y180_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred180 = model.predict( X180_test)\n",
    "y_pred180 = y_pred180.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[2 0 0 ... 0 0 0]\n",
      " [0 4 0 ... 0 0 0]\n",
      " [0 0 3 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 4 0]\n",
      " [0 0 0 ... 0 0 2]]\n",
      "\n",
      "Accuracy: 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y180_test, y_pred180)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y180_test, y_pred180)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Curves Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, title):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    fig, ax = plt.subplots(1, 1)  \n",
    "    ax.grid(b=True, which='major')\n",
    "    ax.grid(b=True, which='minor')\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.show()\n",
    "    val_loss = history.history['val_loss']\n",
    "    min_idx = np.argmin(val_loss)\n",
    "    min_val_loss = val_loss[min_idx]\n",
    "    print('Minimum validation loss of {} reached at epoch {}'.format(min_val_loss, min_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history, title):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    fig, ax = plt.subplots(1, 1)  \n",
    "    ax.grid(b=True, which='major')\n",
    "    ax.grid(b=True, which='minor')\n",
    "    plt.plot(history.history['acc'], label='Train')\n",
    "    plt.plot(history.history['val_acc'], label='Validation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.show()\n",
    "    \n",
    "    val_acc = history.history['val_acc']\n",
    "    max_idx = np.argmax(val_acc)\n",
    "    max_val_acc = val_acc[max_idx]\n",
    "    print('Maximum validation Acc of {} reached at epoch {}'.format(max_val_acc*100, max_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accall(history):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    fig, ax = plt.subplots(1, 1)  \n",
    "    ax.grid(b=True, which='major')\n",
    "    ax.grid(b=True, which='minor')\n",
    "    plt.plot(history.history['acc'], label='Rank-1 Train')\n",
    "    plt.plot(history.history['val_acc'], label='Rank-1 Validation')\n",
    "    plt.plot(history.history['sparse_top_k_categorical_accuracy'], label='Rank-5 Train')\n",
    "    plt.plot(history.history['val_sparse_top_k_categorical_accuracy'], label='Rank-5 Validation')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kacc(history, title):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    fig, ax = plt.subplots(1, 1)  \n",
    "    ax.grid(b=True, which='major')\n",
    "    ax.grid(b=True, which='minor')\n",
    "    plt.plot(history.history['sparse_top_k_categorical_accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_sparse_top_k_categorical_accuracy'], label='Validation')\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss of 0.08292869147380537 reached at epoch 145\n"
     ]
    }
   ],
   "source": [
    "plot_loss(history, 'Train & Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum validation Acc of 97.93242562075667 reached at epoch 145\n"
     ]
    }
   ],
   "source": [
    "plot_acc(history, 'Train & Validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_kacc(history, 'Train & Validation sparse_top_k_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accall(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
